{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example to show detect hand written text using a usb camera. Printing rectangles on recognized text.\n",
    "Press space to capture and space and esc to quit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "# PROXIES IF YOU ARE RUNNING THE JUPYTER NOTEBOOK FROM YOUR LAPTOP\n",
    "proxy = \"http://www:8080\"\n",
    "proxys = \"https://www:8080\"\n",
    "proxyDict = { \"http\"  : proxy, \"https\"  : proxys }\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "def recognize_text_azure(image_path):\n",
    "    subscription_key = ''\n",
    "    assert subscription_key\n",
    "    vision_base_url = \"https://PYTHONCOMPUTERVISION.cognitiveservices.azure.com/vision/v1.0/\"\n",
    "    ocr_url = vision_base_url + \"recognizeText\"\n",
    "    image_data = open(image_path, \"rb\").read()\n",
    "    headers    = {'Ocp-Apim-Subscription-Key': subscription_key, \n",
    "              \"Content-Type\": \"application/octet-stream\" }\n",
    "\n",
    "    params   = {'mode' : 'Handwritten'}\n",
    "    #data     = {'url': image_url}\n",
    "    response = requests.post(ocr_url, headers=headers, params=params, data=image_data)#, proxies=proxyDict)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    operation_url = response.headers[\"Operation-Location\"]\n",
    "\n",
    "    analysis = {}\n",
    "    while not \"recognitionResult\" in analysis:\n",
    "        response_final = requests.get(response.headers[\"Operation-Location\"], headers=headers)#, proxies=proxyDict)\n",
    "        analysis       = response_final.json()\n",
    "        time.sleep(3)\n",
    "\n",
    "    polygons = [(line[\"boundingBox\"], line[\"text\"]) for line in analysis[\"recognitionResult\"][\"lines\"]]\n",
    "\n",
    "    return polygons\n",
    "    \n",
    "    \n",
    "#image = cv2.imread('friends..JPG')\n",
    "def detect_and_show_text():\n",
    "\n",
    "    cam = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "\n",
    "    cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    cv2.namedWindow(\"Text Detector\")\n",
    "    img_counter = 0\n",
    "\n",
    "    while True:\n",
    "        start = time.time()\n",
    "        ret, frame = cam.read()\n",
    "        #CALLING FUNCTION\n",
    "        \n",
    "        cv2.imshow(\"text detector\", frame)\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        k = cv2.waitKey(1)\n",
    "\n",
    "        if k%256 == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        elif k%256 == 32:\n",
    "            # SPACE pressed\n",
    "            img_name = \"temp/opencv_frame_{}.png\".format(img_counter)\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            polygons = recognize_text_azure(img_name)\n",
    "            \n",
    "            image = cv2.imread(img_name)\n",
    "\n",
    "\n",
    "            for polygon in polygons:\n",
    "                vertices = [(polygon[0][i], polygon[0][i+1]) for i in range(0,len(polygon[0]),2)]\n",
    "                text     = polygon[1]\n",
    "                print(text,vertices,' ',' ',vertices[0],vertices[1])\n",
    "                cv2.rectangle(image, vertices[0] , vertices[2],(0, 0, 255), 2)\n",
    "                cv2.putText(image, text, vertices[0], cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "            cv2.imshow('recognized text', image)\n",
    "            while ( cv2.waitKey(0) != 32 ):\n",
    "                time.sleep(1)\n",
    "            img_couqnter += 1\n",
    "            \n",
    "\n",
    "    cam.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detect_and_show_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
