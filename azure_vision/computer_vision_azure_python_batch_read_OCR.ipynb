{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BATCH OCR READ with Computer Vision API  <a name=\"RecognizeText\"> </a>\n",
    "Batch Read File\n",
    "Use this interface to get the result of a Batch Read File operation, employing the state-of-the-art Optical Character Recognition (OCR) algorithms optimized for text-heavy documents. It can handle hand-written, printed or mixed documents. When you use the Batch Read File interface, the response contains a field called \"Operation-Location\". The \"Operation-Location\" field contains the URL that you must use for your Get Read Operation Result operation to access OCR results.​\n",
    "\n",
    "For the result of a Batch Read File operation to be available, it requires an amount of time that depends on the length of the text and the page count. So, you may need to wait before using the Get Read Operation Result operation. The time you need to wait may be up to a few minutes for text-heavy, multi-page images. ​\n",
    "\n",
    "Note: this technology is only available for English text.\n",
    "\n",
    "Set `image_path` to point to the image to be recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTING THE LIBRARIES\n",
    "import requests\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import time\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "# PROXIES IF YOU ARE RUNNING THE JUPYTER NOTEBOOK FROM YOUR LAPTOP\n",
    "proxy = \"http://www.com:8080\"\n",
    "proxys = \"https://www.com:8080\"\n",
    "proxyDict = { \"http\"  : proxy, \"https\"  : proxys }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subscription_key = 'your_key' \n",
    "assert subscription_key\n",
    "\n",
    "image_path = \"your_file.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_base_url = \"https://PYTHONCOMPUTERVISION.cognitiveservices.azure.com/vision/v2.0/\"\n",
    "ocr_url = vision_base_url + \"read/core/asyncBatchAnalyze\"\n",
    "print(ocr_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set image_url to the URL of an image that you want to analyze.\n",
    "\n",
    "image_data = open(image_path, \"rb\").read()\n",
    "headers    = {'Ocp-Apim-Subscription-Key': subscription_key, \n",
    "              \"Content-Type\": \"application/octet-stream\" }\n",
    "\n",
    "\n",
    "response = requests.post(\n",
    "    ocr_url, headers=headers,  data=image_data ) #, proxies=proxyDict)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Extracting text requires two API calls: One call to submit the\n",
    "# image for processing, the other to retrieve the text found in the image.\n",
    "\n",
    "# Holds the URI used to retrieve the recognized text.\n",
    "operation_url = response.headers[\"Operation-Location\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The recognized text isn't immediately available, so poll to wait for completion.\n",
    "'''headers = {\n",
    "    # Request headers\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': '{subscription key}',\n",
    "}'''\n",
    "\n",
    "\n",
    "analysis = {}\n",
    "poll = True\n",
    "while (poll):\n",
    "    response_final = requests.get(\n",
    "        response.headers[\"Operation-Location\"], headers=headers) #, proxies=proxyDict)\n",
    "    analysis = response_final.json()\n",
    "    print(analysis)\n",
    "    time.sleep(1)\n",
    "    if (\"recognitionResults\" in analysis):\n",
    "        poll = False\n",
    "    if (\"status\" in analysis and analysis['status'] == 'Failed'):\n",
    "        poll = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis[\"recognitionResults\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "polygons = []\n",
    "if (\"recognitionResults\" in analysis):\n",
    "    # Extract the recognized text, with bounding boxes.\n",
    "    polygons = [(line[\"boundingBox\"], line[\"text\"]) for line in analysis[\"recognitionResults\"][0][\"lines\"]]\n",
    "\n",
    "#polygons = [(line[\"boundingBox\"], line[\"text\"]) for line in analysis[\"recognitionResult\"][\"lines\"]]\n",
    "\n",
    "\n",
    "# Display the image and overlay it with the extracted text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the recognized text along with the bounding boxes can be extracted as shown in the following line of code. An important point to note is that the handwritten text recognition API returns bounding boxes as **polygons** instead of **rectangles**. Each polygon is _p_ is defined by its vertices specified using the following convention:\n",
    "\n",
    "<i>p</i> = [<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>, ..., <i>x</i><sub>N</sub>, <i>y</i><sub>N</sub>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING RECTANGLES ON RECOGNIZED TEXT\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "#image  = Image.open(BytesIO(requests.get(image_url).content))\n",
    "#image = Image.open(image_path)\n",
    "image = Image.open(\"blank_page_as_background.png\")\n",
    "\n",
    "ax     = plt.imshow(image)\n",
    "for polygon in polygons:\n",
    "    vertices = [(polygon[0][i] * 105, polygon[0][i+1] * 100) for i in range(0,len(polygon[0]),2)]\n",
    "    text     = polygon[1]\n",
    "    #print (text,vertices)\n",
    "    patch    = Polygon(vertices, closed=True,fill=False, linewidth=2, color='y')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(vertices[0][0], vertices[0][1], text, fontsize=8, va=\"top\")\n",
    "_ = plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for polygon in polygons:\n",
    "    vertices = [(polygon[0][i] , polygon[0][i+1] ) for i in range(0,len(polygon[0]),2)]\n",
    "    text     = polygon[1]\n",
    "    if \"nspec\" in text:\n",
    "        print (text,vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "ms_docs_meta": {
   "author": "JuliaNik",
   "description": "Get information and code samples to help you quickly get started using Python and the Computer Vision API in Microsoft Cognitive Services.",
   "manager": "ytkuo",
   "ms.author": "juliakuz",
   "ms.date": "02/02/2018",
   "ms.service": "cognitive-services",
   "ms.technology": "computer-vision",
   "ms.topic": "article",
   "services": "cognitive-services",
   "title": "Computer Vision API Python quick start | Microsoft Docs",
   "titleSuffix": "Computer Vision API Python quick start | Microsoft Cognitive Services"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
