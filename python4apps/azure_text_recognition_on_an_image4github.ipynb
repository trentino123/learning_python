{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE ON HOW TO MAKE A TEXT RECOGNITION FROM AN IMAGE IN AZURE\n",
    "### This example includes handwritten and non-handwritten text, other options are available from Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = \"http://fillyourproxy.com:8080\" \n",
    "os.environ['https_proxy'] = \"https://fillyourproxy.com:8080\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# AZURE  TEXT RECOGNITION\n",
    "##########################################\n",
    "\n",
    "def recognize_text_azure(image_path):\n",
    "    from PIL import Image\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.collections import PatchCollection\n",
    "    from matplotlib.patches import Rectangle\n",
    "    from matplotlib.patches import Polygon\n",
    "    import requests\n",
    "    import time\n",
    "    \n",
    "    subscription_key = 'asdfasdfasdf2341235f52e45f8dc862'\n",
    "    assert subscription_key\n",
    "    vision_base_url = \"https://PYTHONTEST.cognitiveservices.azure.com/vision/v1.0/\"\n",
    "    ocr_url = vision_base_url + \"recognizeText\"\n",
    "    image_data = open(image_path, \"rb\").read()\n",
    "    headers    = {'Ocp-Apim-Subscription-Key': subscription_key, \n",
    "              \"Content-Type\": \"application/octet-stream\" }\n",
    "\n",
    "    params   = {'mode' : 'Handwritten'}\n",
    "    #data     = {'url': image_url}\n",
    "    response = requests.post(ocr_url, headers=headers, params=params, data=image_data)#, proxies=proxyDict)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    operation_url = response.headers[\"Operation-Location\"]\n",
    "\n",
    "    analysis = {}\n",
    "    while not \"recognitionResult\" in analysis:\n",
    "        response_final = requests.get(response.headers[\"Operation-Location\"], headers=headers)#, proxies=proxyDict)\n",
    "        analysis       = response_final.json()\n",
    "        time.sleep(1)\n",
    "\n",
    "    polygons = [(line[\"boundingBox\"], line[\"text\"]) for line in analysis[\"recognitionResult\"][\"lines\"]]\n",
    "\n",
    "    plt.figure(figsize=(25,25))\n",
    "    #image  = Image.open(BytesIO(requests.get(image_url).content))\n",
    "    image = Image.open(image_path)\n",
    "    ax     = plt.imshow(image)\n",
    "    for polygon in polygons:\n",
    "        vertices = [(polygon[0][i], polygon[0][i+1]) for i in range(0,len(polygon[0]),2)]\n",
    "        text     = polygon[1]\n",
    "        print(text,vertices)\n",
    "        patch    = Polygon(vertices, closed=True,fill=False, linewidth=2, color='y')\n",
    "        ax.axes.add_patch(patch)\n",
    "        plt.text(vertices[0][0], vertices[0][1], text, fontsize=15, va=\"top\", color='g')\n",
    "    plt.savefig(image_path )\n",
    "    #plt.close(fig)\n",
    "    _ = plt.axis(\"off\")\n",
    "\n",
    "\n",
    "    return polygons\n",
    "\n",
    "##########################################\n",
    "# AZURE END TEXT RECOGNITION\n",
    "##########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recognize_text_azure('forms/cv2BRCP-DIEXT-I5LEU-1907211539209.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
